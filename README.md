# LLM API Gateway Lambda

This AWS Lambda function serves as an API gateway for multiple LLM providers, including OpenAI, Google Gemini, Anthropic, AWS Bedrock, and Ollama. It processes incoming requests, selects the appropriate model, and generates responses using the selected provider.

## Features

- Supports multiple LLM providers:
  - OpenAI (GPT models)
  - Google Gemini
  - Anthropic (Claude models)
  - AWS Bedrock (Amazon Titan, Mistral, Meta-Llama, etc.)
  - Ollama
- Secure API key handling via AWS Secrets Manager.
- Handles JSON input validation and error management.
- Logs errors and exceptions for debugging.
- Supports custom model parameters.

## Dependencies

This Lambda function relies on the following Python packages:

- `dill`
- `json`
- `os`
- `traceback`
- `langchain_openai`
- `langchain_google_genai`
- `langchain_anthropic`
- `langchain_aws`
- `langchain_ollama`
- `nemoguardrails`
- `loadsecrets`

## Environment Variables

| Environment Variable     | Description                 |
|-------------------------|-----------------------------|
| `BASE_APIGW_URL`       | API Gateway base URL for routing requests |
| `APIGW_KEY`            | API Gateway key for authentication |
| `ANTHROPIC_API_KEY`    | API key for Anthropic models |
| `OPENAI_API_KEY`       | API key for OpenAI models |
| `GOOGLE_API_KEY`       | API key for Google Gemini models |

These secrets are loaded dynamically using the `load_secrets` function.

## Function Overview

### `get_model(provider, model_name, messages, base_url, **kwargs)`

Creates and returns a pickled model instance based on the specified provider.

#### Parameters:
- `provider` (str): LLM provider (`openai`, `google`, `anthropic`, `bedrock`, `ollama`).
- `model_name` (str): Name of the model (e.g., `gpt-4`, `gemini-pro`, `claude-3`).
- `messages` (list): List of message exchanges to process.
- `base_url` (str): Base API URL.
- `**kwargs`: Additional parameters passed to the model.

#### Returns:
- A response generated by the selected model.

#### Supported Providers:
- **OpenAI:** Uses `ChatOpenAI` from LangChain.
- **Google:** Uses `ChatGoogleGenerativeAI` from LangChain.
- **Anthropic:** Uses `ChatAnthropic` from LangChain.
- **AWS Bedrock:** Uses `ChatBedrock` from LangChain.
- **Ollama:** Uses `ChatOllama` from LangChain.

### `lambda_handler(event, context)`

AWS Lambda entry point. Handles incoming API requests, validates input, and returns the generated LLM response.

#### Expected Input (JSON format in `event["body"]`):
```json
{
  "provider": "openai",
  "model_name": "gpt-4",
  "messages": [{"role": "user", "content": "Hello, how are you?"}],
  "params": {}
}
